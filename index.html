<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-163784922-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};
  //JS: "||" is OR function, push() is append()
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-163784922-1');
</script>

  <title>Yash Kant</title>

  <meta name="author" content="Yash Kant">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="data/yashcircle.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yash Kant</name>
              </p>
              <p>I am a Research Visitor at Georgia Tech supervised by <a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a>, <a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>, <a href="https://panderson.me">Peter Anderson</a>, and <a href="https://dexter1691.github.io">Harsh Agrawal</a>. Presently, I am working on the intersection of Computer Vision and Natural Language Processing.
              </p>
                <p>I finished my undergraduate studies from <a href="http://iitr.ac.in">Indian Institute of Technology Roorkee</a>. I have interned at <a href="https://www.microsoft.com/en-in/msidc/bangalore-campus.aspx">Microsoft, Bangalore</a> and visited <a href="http://www.nus.edu.sg/">National University of Singapore</a> twice as a research assistant.<p>
              <p style="text-align:center">
                <a href="mailto:ysh.kant@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/cv-yashkant.pdf" onclick="ga('send', 'event', 'Videos', 'play', 'Fall Campaign')">CV</a> &nbsp/&nbsp
                <a href="https://github.com/yashkant"> Github </a> &nbsp/&nbsp
                <a href="https://twitter.com/yash2kant">Twitter</a> &nbsp/&nbsp
                <a href="https://in.linkedin.com/in/yash-kant/"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://www.instagram.com/kash_yant/">Instagram</a> &nbsp/&nbsp
                <a href="https://www.facebook.com/yshkant">Facebook</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="data/yashkant.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="data/yashkant.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Projects </heading>
<!--              <p>My recent projects were</p>-->
              <p class="content">
              <ul>
              <li><b><i>Adding Complement Objective Training to Pythia:</i></b> I experimented with adding Complement Objective Training in FAIR's vision and language framework <a href="https://github.com/facebookresearch/pythia/">Pythia</a> and also wrote a report on my findings <a href="https://drive.google.com/file/d/16NtLvZvBPq1cRVeCSq7sXXg0C8NkSi4l/view">here</a>, the code is <a href="https://github.com/facebookresearch/pythia/pull/32">here</a>. </li>
              <li><b><i>ICLR Reproducibility Challenge:</i></b> We reproduced <a href="https://arxiv.org/abs/1806.06763">Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks </a> and here's the <a href="https://github.com/yashkant/Padam-Tensorflow">code.</a></li>
              <li><b><i>Visual Chatbot Version 2.0 (<a href="https://github.com/Cloud-CV/visual-chatbot/pull/18">here</a>):</i></b> I shifted the old Lua-Torch codebase to PyTorch, added better captioning and trained the VisDial model on BUTD features.</li>
              <li><b><i>Quantized Neural Architecture Search (unreleased):</i></b>  I quantized the search space of Neural Architecture Search algorithms [<a href="https://arxiv.org/abs/1802.03268">ENAS</a> and <a href="https://arxiv.org/abs/1712.00559">PNAS</a>] to search for resource-efficient models.</li>
              </ul>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research
              </heading>
            </td>
          </tr>
        </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          <tbody>
          <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id="lh_image" style="opacity: 0;"><video muted="" autoplay="" loop="" width="100%" height="100%">
                <source src="data/sam-textvqa/textvqa-workshop.gif" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src="data/sam-textvqa/textvqa-workshop.gif" width="180">
              </div>
              <script type="text/javascript">
                function lighthouse_start() {
                  document.getElementById('lh_image').style.opacity = "1";
                }

                function lighthouse_stop() {
                  document.getElementById('lh_image').style.opacity = "0";
                }
                lighthouse_stop()
              </script>
            </td>

            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2007.12146">
                <papertitle>Spatially Aware MultiModal Transformers for TextVQA</papertitle>
              </a>
              <br>
              <strong>Yash Kant</strong>,
              <a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>,
              <a href="https://panderson.me/">Peter Anderson</a>,
              <a href="https://www.cc.gatech.edu/~jlu347/">Jiasen Lu</a>,
              <a href="https://www.alexander-schwing.de/">Alexander Schwing</a>,
              <a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a>,
              <a href="https://dexter1691.github.io/">Harsh Agrawal</a>
              <br>
              <em>European Conference on Computer Vision 2020</em>
              <br>
              <p></p>
              <p>We propose a novel spatially aware self-attention layer such that each visual entity only looks at neighboring entities defined by a spatial graph and use it to solve TextVQA.</p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                I borrowed this template from Jon Barron's<a href="https://github.com/jonbarron/jonbarron_website"> website</a>.
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
